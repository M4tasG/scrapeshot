- Save the links that were already scraped
    - CSV file?
    - JSON file?
    - Shared DB for multiple scrapers?

- Options to scrape
    - Random links
    - Ordered links (https://prnt.sc/[a-z-0-9][a-z-0-9][etc.])
    - Amount of links (Random 100, Random 10000, Ordered 10)

- Find out why some images that are saved are showing as unsupported or corrupted
- Edge-Cases (currently only one that is being handled if a picture has been removed)
- Threading

- Possibly included image recognition to categorize the scraped images
    - Detect documents, chats, game screenshots etc. (very big ?)
    - Filter out no longer available images